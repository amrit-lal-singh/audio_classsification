{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tflite-support in /home/amrit/.local/lib/python3.8/site-packages (0.4.3)\n",
      "Requirement already satisfied: pybind11>=2.6.0 in /home/amrit/.local/lib/python3.8/site-packages (from tflite-support) (2.11.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/amrit/.local/lib/python3.8/site-packages (from tflite-support) (1.4.0)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /home/amrit/.local/lib/python3.8/site-packages (from tflite-support) (0.4.6)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/amrit/.local/lib/python3.8/site-packages (from tflite-support) (23.3.3)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/amrit/.local/lib/python3.8/site-packages (from tflite-support) (1.23.5)\n",
      "Requirement already satisfied: protobuf<4,>=3.18.0 in /home/amrit/.local/lib/python3.8/site-packages (from tflite-support) (3.20.3)\n",
      "Requirement already satisfied: CFFI>=1.0 in /home/amrit/.local/lib/python3.8/site-packages (from sounddevice>=0.4.4->tflite-support) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/amrit/.local/lib/python3.8/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite-support) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install tflite-support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-28 16:19:09.013021: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-28 16:19:09.058421: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-28 16:19:09.059258: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-28 16:19:09.921694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from tflite_support.task import audio\n",
    "from tflite_support.task import core\n",
    "from tflite_support.task import processor\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "# Initialization\n",
    "base_options = core.BaseOptions(file_name=\"soundclassifier.tflite\")\n",
    "classification_options = processor.ClassificationOptions(max_results=2)\n",
    "options = audio.AudioClassifierOptions(base_options=base_options, classification_options=classification_options)\n",
    "classifier = audio.AudioClassifier.create_from_options(options)\n",
    "\n",
    "def record_audio(seconds=2, fs=44100):\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16, channels=1, rate=fs, input=True, frames_per_buffer=fs)\n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "    for _ in range(int(fs * seconds / fs)):\n",
    "        data = stream.read(fs)\n",
    "        frames.append(np.frombuffer(data, dtype=np.int16))\n",
    "    print(\"Finished recording.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    audio_data = np.concatenate(frames)\n",
    "    return audio_data\n",
    "\n",
    "def save_audio_data(audio_data, file_path):\n",
    "    sf.write(file_path, audio_data, samplerate=44100, format='wav')\n",
    "\n",
    "def create_spectrogram(audio_data, image_file):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "\n",
    "    # Convert audio data to floating-point format\n",
    "    audio_data_float = audio_data.astype(np.float32)\n",
    "    \n",
    "    # Compute mel spectrogram\n",
    "    ms = librosa.feature.melspectrogram(y=audio_data_float, sr=44100)\n",
    "    log_ms = librosa.power_to_db(ms, ref=np.max)\n",
    "    \n",
    "    # Display mel spectrogram\n",
    "    librosa.display.specshow(log_ms, sr=44100)\n",
    "\n",
    "    # Save figure as image\n",
    "    fig.savefig(image_file)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n",
      "Classification Results:\n",
      "Category: 0 Background Noise, Score: 0.9940126538276672\n",
      "Category: 3 Gunshots, Score: 0.003293450688943267\n",
      "Recording...\n",
      "Finished recording.\n",
      "Classification Results:\n",
      "Category: 0 Background Noise, Score: 0.8954781293869019\n",
      "Category: 3 Gunshots, Score: 0.07009774446487427\n",
      "Recording...\n",
      "Finished recording.\n",
      "Classification Results:\n",
      "Category: 3 Gunshots, Score: 0.3668978810310364\n",
      "Category: 0 Background Noise, Score: 0.3142758309841156\n",
      "Recording...\n",
      "Finished recording.\n",
      "Classification Results:\n",
      "Category: 0 Background Noise, Score: 0.9646139740943909\n",
      "Category: 1 Clapping, Score: 0.025540195405483246\n",
      "Recording...\n",
      "Finished recording.\n",
      "Classification Results:\n",
      "Category: 0 Background Noise, Score: 0.9896882176399231\n",
      "Category: 2 Glass Breaking, Score: 0.00433580856770277\n",
      "Recording...\n",
      "Finished recording.\n",
      "Classification Results:\n",
      "Category: 0 Background Noise, Score: 0.9975818395614624\n",
      "Category: 3 Gunshots, Score: 0.0014339103363454342\n",
      "Recording...\n",
      "Finished recording.\n",
      "Classification Results:\n",
      "Category: 0 Background Noise, Score: 0.617608368396759\n",
      "Category: 4 Scream, Score: 0.11705957353115082\n",
      "Recording...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Record audio for two seconds\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     recorded_audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecord_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Save the recorded audio data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     save_audio_data(recorded_audio, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecorded_audio.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m, in \u001b[0;36mrecord_audio\u001b[0;34m(seconds, fs)\u001b[0m\n\u001b[1;32m     23\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(fs \u001b[38;5;241m*\u001b[39m seconds \u001b[38;5;241m/\u001b[39m fs)):\n\u001b[0;32m---> 25\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint16))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished recording.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pyaudio.py:608\u001b[0m, in \u001b[0;36mStream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    606\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Record audio for two seconds\n",
    "    recorded_audio = record_audio()\n",
    "\n",
    "    # Save the recorded audio data\n",
    "    save_audio_data(recorded_audio, 'recorded_audio.wav')\n",
    "\n",
    "    # Run inference\n",
    "    audio_file = audio.TensorAudio.create_from_wav_file(\"recorded_audio.wav\", classifier.required_input_buffer_size)\n",
    "    audio_result = classifier.classify(audio_file)\n",
    "\n",
    "    # Print the classification result\n",
    "    print(\"Classification Results:\")\n",
    "    for classification in audio_result.classifications:\n",
    "        for category in classification.categories:\n",
    "            print(f\"Category: {category.category_name}, Score: {category.score}\")\n",
    "\n",
    "    # Uncomment the below line if you want to create and save the spectrogram\n",
    "    # create_spectrogram(recorded_audio, 'recorded_spectrogram.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
